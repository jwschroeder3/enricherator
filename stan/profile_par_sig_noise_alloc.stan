functions {
    // Taken straight from stan code generated by brms
    /* Efficient computation of the horseshoe prior
        * see Appendix C.1 in https://projecteuclid.org/euclid.ejs/1513306866
        * Args:
        *   z: standardized population-level coefficients
        *   lambda: local shrinkage parameters
        *   tau: global shrinkage parameter
        *   c2: slab regularization parameter
        * Returns:
        *   population-level coefficients following the horseshoe prior
    */
    vector horseshoe(vector z, vector lambda, real tau, real c2) {
        int K = rows(z);
        vector[K] lambda2 = square(lambda);
        // eq 2.8 in piironen and vehtari
        vector[K] lambda_tilde = sqrt(c2 * lambda2 ./ (c2 + tau^2 * lambda2));
        return z .* lambda_tilde * tau;
    }

    /* For parallel mapping of likelihood calculation
        * Args:
        *   globals: parameters common across all jobs (frac_signal), samp_prec
        *   locals: parameters local to each job, y_hat
        *   x: will be libsize
        *   y: the counts, sample_type array of length 2
    */
    vector map_loglik(
            vector globals,
            vector y_hat_signal,
            array[] real x_r,
            array[] int x_i
    ) {

        real ll;
        real libsize = x_r[1];
        int y = x_i[1];
        // the sample precisions are elements 1 and 2 of globals
        real samp_prec = globals[x_i[3]];
        // signoise is in the rest, starting at index 3 of globals
        real log_signoise_s = globals[2 + x_i[2]*2-1];
        real log_comp_signoise_s = globals[2 + x_i[2]*2];

        ll = log_sum_exp(
            log_signoise_s + neg_binomial_2_log_lpmf(y | y_hat_signal[1], samp_prec),
            log_comp_signoise_s + poisson_log_lpmf(y | libsize)
        );

        return [ll]';
    }

    //real loglik_part_sum_lpmf(
    //        int[] y_sq_slice,
    //        int start,
    //        int end,
    //        vector alpha_gq,
    //        vector beta_gq,
    //        real log_signoise_s,
    //        real log_comp_signoise_s,
    //        real samp_prec,
    //        real libsize_s,
    //        int sample_type
    //) {

    //    vector[end-start+1] y_hat_signal = alpha_gq[start:end]
    //        + sample_type * beta_gq[start:end]
    //        + libsize_s;
    //    //print("n_elems in y_hat_siganl: ", num_elements(y_hat_signal));
    //    //print("n_elems in y_sq_slice: ", num_elements(y_sq_slice));
    //    real sum = 0;
    //    int idx = 1;
    //    for (i in start:end) {
    //        idx = i-start+1;
    //        //print("i: ", i);
    //        sum += log_sum_exp(
    //            log_signoise_s + neg_binomial_2_log_lpmf(y_sq_slice[idx] | y_hat_signal[idx], samp_prec),
    //            log_comp_signoise_s + poisson_log_lpmf(y_sq_slice[idx] | libsize_s)
    //        );
    //    }
    //    return sum;
    //}


}

data {
    int<lower=1> N; // number of observations: L*Q*S;
    int<lower=1> L; // number of positions
    int<lower=1> S; // number of samples
    int<lower=1> B; // number of betas
    int<lower=1> A; // number of alphas
    int<lower=1> G; // number of genotypes
    int<lower=1, upper=2> Q; // number of strands

    real alpha_prior;

    array[S] int geno_x; // genotype for each sample
    array[S] int sample_x; // sample_id for each datum
    //array[S] real<lower=0> libsize; // exposure term for each sample

    array[N,3] int X_i; // for each N, the (count, genotype_id, strand_id, sample_type)
    array[N,1] real X_r; // for each N, the centered_log_libsize

    array[S] real cent_loglibsize;

    real<lower=0> hs_df; // local df
    real<lower=0> hs_df_global; // global df
    real<lower=0> hs_df_slab; // slab df
    real<lower=0> hs_scale_global; // global prior scale
    real<lower=0> hs_scale_slab; // slab prior scale

    int<lower=1> a_sub_L;
    int<lower=1> b_sub_L;
    int<lower=1> b_num_non_zero;
    vector<lower=0,upper=1>[b_num_non_zero] b_weights_vals;
    array[b_num_non_zero] int b_col_accessor;
    array[L+1] int b_row_non_zero_number;
    int<lower=1> a_num_non_zero;
    vector<lower=0,upper=1>[a_num_non_zero] a_weights_vals;
    array[a_num_non_zero] int a_col_accessor;
    array[L+1] int a_row_non_zero_number;

    //int<lower=0, upper=1> gather_log_lik;
}

transformed data {
    //array[S] real cent_loglibsize;
    int num_hs = b_sub_L*B*Q;
    //{
    //    array[S] real log_libsize;
    //    real mean_loglib;
    //    for (s in 1:S) {
    //        log_libsize[s] = log(libsize[s]);
    //    }
    //    mean_loglib = mean(log_libsize);
    //    for (s in 1:S) {
    //        cent_loglibsize[s] = log_libsize[s] - mean_loglib;
    //    }
    //}
}

parameters {
    vector<lower=0, upper=1>[S] sig_noise; // signal-to-noise allocation for each sample
    //vector[S] wsh; // wsh term for how much wsh for a given sample
    vector<lower=0>[2] prec; // stratify global precision inference by extracted vs input
    array[G,Q] vector[a_sub_L] sub_Alpha; // one intercept for each genotype/sub-position
    array[B,Q] vector[b_sub_L] sub_Beta; // one beta for each genotype/sub-position
    vector[B] Gamma; // an intercept to offset hbd samples by

    // local parameters for horseshoe prior
    array[B,Q] vector[b_sub_L] zbeta;
    array[B,Q] vector<lower=0>[b_sub_L] hs_local;
    // horseshoe shrinkage parameters 
    real<lower=0> hs_global; 
    real<lower=0> hs_slab; 
    real<lower=0> shape; 
}

transformed parameters {
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
// how might these be rearranged, or not, to get map_rect working?
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
    array[B,Q] vector[L] Beta;
    array[G,Q] vector[L] Alpha; // one intercept for each genotype/position combination

    real lprior = 0.0;

    {
        //array[B,Q] vector[b_sub_L] sub_Beta
        vector[b_sub_L] sub_Beta; // one intercept for each genotype/sub-position
        vector[L] tmp_Beta;
        for (b in 1:B) {
            for (q in 1:Q) {
                print(sub_Beta
                sub_Beta = horseshoe(
                    zbeta[b,q],
                    hs_local[b,q],
                    hs_global,
                    hs_scale_slab^2 * hs_slab
                );
                tmp_Beta = csr_matrix_times_vector(
                    L,
                    b_sub_L,
                    b_weights_vals,
                    b_col_accessor,
                    b_row_non_zero_number,
                    sub_Beta
                );
                Beta[b,q] = tmp_Beta + Gamma[b];
            }
        }
    }

    for (g in 1:G) {
        for (q in 1:Q) {
            Alpha[g,q] = csr_matrix_times_vector(
                L,
                a_sub_L,
                a_weights_vals,
                a_col_accessor,
                a_row_non_zero_number,
                sub_Alpha[g,q]
            );
        }
    }

    lprior += student_t_lpdf(hs_global | hs_df_global, 0, hs_scale_global)
        - 1 * log(0.5);
    lprior += inv_gamma_lpdf(hs_slab | 0.5 * hs_df_slab, 0.5 * hs_df_slab);
    lprior += gamma_lpdf(shape | 0.01, 0.01);

    for (b in 1:B) {
        for (q in 1:Q) {
            lprior += std_normal_lpdf(zbeta[b,q]);
            lprior += student_t_lpdf(hs_local[b,q] | hs_df, 0, 1)
              - num_hs * log(0.5);
        }
    }

    for (g in 1:B) {
        for (q in 1:Q) {
            lprior += normal_lpdf(sub_Alpha[g,q] | alpha_prior, 4);
        }
    }

    lprior += student_t_lpdf(Gamma | 3, 0, 5);
    lprior += beta_lpdf(sig_noise | 25.0, 1.0);
}

model {
    int sample_type;
    int genotype;
    array[N] vector[1] Y_hat_signal;
    //real Y_hat_noise;
    //real wsh_s;
    real libsize_s;
    real log_signoise_s;
    real log_comp_signoise_s;
    //int end_n;
    //int start_n = 1;
    vector[S] log_signoise = log(sig_noise);
    vector[S] log_comp_signoise = log1m(sig_noise);
    vector[2+S*2] prec_signoise;

    target += lprior;

    prec ~ lognormal(0, 1);

    prec_signoise[1] = prec[1];
    prec_signoise[2] = prec[2];

    int row_idx = 1;
    for (s in 1:S) {
        log_signoise_s = log_signoise[s];
        log_comp_signoise_s = log_signoise[s];
        prec_signoise[2+s*2-1] = log_signoise_s;
        prec_signoise[2+s*2] = log_comp_signoise_s;
        sample_type = sample_x[s];
        genotype = geno_x[s];
        //wsh_s = wsh[s];
        libsize_s = cent_loglibsize[s];

        for (q in 1:Q) {
            //end_n = start_n + L - 1;
            for (l in 1:L) {
                Y_hat_signal[row_idx][1] = Alpha[genotype,q][l]
                    + sample_type * Beta[genotype,q][l]
                    + libsize_s;
                row_idx += 1;
            }
            //Y_hat_signal[start_n:end_n] = Alpha[genotype,q]
            //    + sample_type * Beta[genotype,q]
            //    + libsize_s;
            //start_n = end_n + 1;
        }
    }

    /* Needs:
    1. ys - 2D array, N-by-something, each row will be passed to map_rect
    2. xs - 2D array, N-by-something, each row will be passed to map_rect
    3. global_params - 
    4. local_params - Y_hat_signal, array of real
    */


    // xs and Y are Q*L x S arrays so that map_rect parallelizes over Q*L
    // Y is just the counts
    // xs should contain libsize_s and sample_type so we can calculate Y_hat for each Q/L
    //
    // arrange globals to be 
    target += sum(map_rect(map_loglik, prec_signoise, Y_hat_signal, X_r, X_i));

    //for (s in 1:S) {
    //    sample_type = sample_x[s];
    //    genotype = geno_x[s];
    //    //wsh_s = wsh[s];
    //    libsize_s = cent_loglibsize[s];
    //    log_signoise_s = log_signoise[s];
    //    log_comp_signoise_s = log_signoise[s];
    //    samp_prec = prec[sample_type+1];

    //    globals[1] = libsize_s;
    //    globals[2] = samp_prec;
    //    globals[3] = log_signoise_s;
    //    globals[4] = log_comp_signoise_s;
    //    globals[5] = sample_type;
    //    for (q in 1:Q) {
            //Y_hat_signal = Alpha[genotype,q]
            //    + sample_type * Beta[genotype,q]
            //    + libsize_s;
            //}
            //y_sq = Y[s,q];
 

            //target += reduce_sum(
            //    loglik_part_sum_lpmf,
            //    y_sq,
            //    grainsize,
            //    alpha_gq,
            //    beta_gq,
            //    log_signoise_s,
            //    log_comp_signoise_s,
            //    samp_prec,
            //    libsize_s,
            //    sample_type
            //);
            //for (l in 1:L) {
            //   
            //    // allocates counts proportionally to signal/noise,
            //    // where noise is just a fraction of libsize
            //    target += log_sum_exp(
            //        log_signoise_s + neg_binomial_2_log_lpmf(Y[s,q,l] | Y_hat_signal[l], prec[sample_type+1]),
            //        log_comp_signoise_s + poisson_log_lpmf(Y[s,q,l] | libsize_s)
            //    );
            //}
    //    }
    //}
}

generated quantities {
    //vector[N] log_lik;
    //array[S,Q] vector[L] post_pred;
    //{
    //    vector[L] Y_hat_signal_sq;
    //    vector[L] Y_hat_noise_sq;
    //    int n = 1;
    //    int genotype;
    //    int sample_type;
    //    //if (gather_log_lik) {
    //        for (s in 1:S) {
    //            sample_type = sample_x[s];
    //            genotype = geno_x[s];
    //            for (q in 1:Q) {
    //                Y_hat_signal_sq = Alpha[genotype,q]
    //                    + sample_type * Beta[genotype,q]
    //                    + cent_loglibsize[s];
    //                Y_hat_noise_sq = wsh[s] + cent_loglibsize[s];
    //                for (l in 1:L) {
    //                    post_pred[s,q][l] = error neg_binomial_2_rng(exp(Y_hat_sq[l]), prec[sample_type+1]);
    //                    log_lik[n] = error neg_binomial_2_log_lpmf(Y[s,q,l] | Y_hat_sq[l], prec[sample_type+1]);
    //                    n += 1;
    //                }
    //            }
    //        }
    //    //}
    //}
}

